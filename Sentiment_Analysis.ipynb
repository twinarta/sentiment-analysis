{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNU9Tzb47/QP0WUX1zuIYHP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twinarta/sentiment-analysis/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis using Python\n",
        "8 January 2023, run using Google Colab (CPU, free)"
      ],
      "metadata": {
        "id": "rdlcwiyjqMHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependency\n",
        "\n",
        "In this case, the dependency is Huggingface's Transformers library that is used to load sentiment analysis model and make a prediction. The torch variant is used to save time and disk space (instead of both the PyTorch and TensorFlow version)."
      ],
      "metadata": {
        "id": "P1OLu3DqqQGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'transformers[torch]'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWPEIv-KBEfF",
        "outputId": "ff18311e-832d-4e5c-abac-e67e6f8b2c0f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "Importing libraries, in this case Huggingface's Transformers and regex for text processing purposes"
      ],
      "metadata": {
        "id": "qNB-D_k5qlVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import re"
      ],
      "metadata": {
        "id": "6sZwjsOREhl6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the sentiment analysis pretrained model from Huggingface\n",
        "\n",
        "Using Roberta as the architecture of the model, specifically used for English language. The model will return 3 classes (positive, negative, neutral). Roberta is a fairly large model that runs quite fast even using CPU (less than 0.5 seconds for around 10 words on a Intel i3 machine)."
      ],
      "metadata": {
        "id": "J66RiPr9qtER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_pipeline = pipeline(\"text-classification\", model=\"j-hartmann/sentiment-roberta-large-english-3-classes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMc3X0btEkkp",
        "outputId": "e10638a7-f18f-4a34-e326-61bab7a89ac5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at j-hartmann/sentiment-roberta-large-english-3-classes were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `sentiment_pipeline` variable will act as the global variable that will be accessed to make an inference, instead of instantiating a new variable that holds the model over and over again as the `analyze_sentiment` function is called.\n",
        "\n",
        "The pipeline will also automatically preprocess the input text to be processed by the model (tokenization, embedding generation, reshape to match input size)."
      ],
      "metadata": {
        "id": "HabQgtOKzL4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions to preprocess raw text\n",
        "\n",
        "1. Remove all characters except alphabets (uppercase and lowercase), comma, dot, apostrophe, and single whitespace.\n",
        "2. Remove tags (XML or HTML tags)\n",
        "3. Remove multiple whitespaces (if any)\n",
        "4. Remove all non-ascii characters\n",
        "5. Remove emojis\n",
        "\n",
        "In this case, these functions are prepared to determine the sentiment of English texts."
      ],
      "metadata": {
        "id": "mxVNnC38q724"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_misc_characters(text):\n",
        "  return re.sub(\"[^A-Za-z,.' ]+\", '', text)\n",
        "\n",
        "def remove_tags(text):\n",
        "  return re.sub('<[^<]+?>', '', text)\n",
        "\n",
        "def remove_multiple_whitespaces(text):\n",
        "  return \" \".join(text.split())\n",
        "\n",
        "def clean_unicode(text):\n",
        "  return (text.encode('ascii', 'ignore')).decode(\"utf-8\")\n",
        "\n",
        "# From: https://stackoverflow.com/a/58356570\n",
        "def remove_emojis(data):\n",
        "    emoj = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "    return re.sub(emoj, '', data)"
      ],
      "metadata": {
        "id": "v_xPU6U9FYWP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine the functions\n",
        "\n",
        "A preprocess function combines the functions above with the following steps:\n",
        "1. Remove all non-ascii characters\n",
        "2. Remove all emojis\n",
        "3. Remove multiple whitespaces (ensuring there are only single spaces from now own)\n",
        "4. Remove HTML/XML tags (for instance, `<div></div>` or `<span></span>`\n",
        "5. Remove all characters except alphabets (uppercase and lowercase), comma, dot, apostrophe, and single whitespace\n",
        "6. Convert the preprocessed text into lowercase text\n",
        "7. Remove all trailing whitespace found in the text\n",
        "\n",
        "If the resulted text is empty, return null as the result"
      ],
      "metadata": {
        "id": "9fgd-caRr408"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  if text is None:\n",
        "    return None\n",
        "\n",
        "  preprocessed = clean_unicode(text)\n",
        "  preprocessed = remove_emojis(text)\n",
        "  preprocessed = remove_multiple_whitespaces(preprocessed)\n",
        "  preprocessed = remove_tags(preprocessed)\n",
        "  preprocessed = remove_misc_characters(preprocessed)\n",
        "  preprocessed = preprocessed.lower()\n",
        "  preprocessed = preprocessed.strip()\n",
        "\n",
        "  if len(preprocessed) > 0:\n",
        "    return preprocessed\n",
        "\n",
        "  return None"
      ],
      "metadata": {
        "id": "dqOX0cMEp0r-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to predict the sentiment of text\n",
        "\n",
        "The function accesses the sentiment_pipeline variable as a global variable.\n",
        "\n",
        "After the text is subjected to the preprocess() function, there are several condititions used to validate the text:\n",
        "1. The text can't be null\n",
        "2. The number of words needs to be larger or equal to 3, to ensure that the sentence is not too short\n",
        "3. The number of words needs to be less than 20, since long sentences may produce inaccurate result because the context might be too large (the average number of word found in a sentence is 15-20 words).\n",
        "4. Ensuring that list that is returned as the prediction result is valid in terms of the size of the list and the index of the dictionary.\n",
        "5. A threshold is set to ensure that the inference result's score is higher than a certain number (in this case, 0.6). This is done to only trust prediction result with high confidence score."
      ],
      "metadata": {
        "id": "XqxzgGJrtREO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text):\n",
        "  global sentiment_pipeline\n",
        "\n",
        "  confidence_threshold = 0.6\n",
        "\n",
        "  text = preprocess(text)\n",
        "\n",
        "  if text is None:\n",
        "    return None\n",
        "\n",
        "  words = text.split(\" \")\n",
        "\n",
        "  if len(words) < 3:\n",
        "    return None\n",
        "\n",
        "  if len(words) > 20:\n",
        "    return None\n",
        "\n",
        "  result = sentiment_pipeline(text)\n",
        "\n",
        "  sentiment_result = None\n",
        "\n",
        "  if len(result) > 0:\n",
        "    if 'score' not in result[0].keys() or 'label' not in result[0].keys():\n",
        "      return None\n",
        "\n",
        "    if result[0]['score'] >= confidence_threshold:\n",
        "      sentiment_result = result[0]['label'].lower()\n",
        "\n",
        "  return sentiment_result"
      ],
      "metadata": {
        "id": "wLjLxEG7iVXX"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the function\n",
        "\n",
        "Here are some regular sentence that produces the 3 classes (positive, negative, and neutral), representing the positive test cases."
      ],
      "metadata": {
        "id": "YrIvDDmOuqG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positive test cases"
      ],
      "metadata": {
        "id": "m7bFxBWazsec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neutral"
      ],
      "metadata": {
        "id": "j6MSKR0DwRqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = analyze_sentiment(\"I ate a sandwhich\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AgZ7BItozmU",
        "outputId": "af6900cf-4109-4811-8067-df2f1b50759c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positive"
      ],
      "metadata": {
        "id": "Xuscc7IOwUSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = analyze_sentiment(\"I really like this food!\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6daxBttu3E_",
        "outputId": "70bda166-4ca2-4de6-ec01-fd303744281f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Negative"
      ],
      "metadata": {
        "id": "_t9KNIxuwWmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = analyze_sentiment(\"This is not what I ordered\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeRkVr_5wNAL",
        "outputId": "521f70a6-f676-488c-e7f7-f6c1e40c1571"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cases in which no explicit positive/negative word is mentioned\n",
        "\n",
        "Here are several test cases in which no positive/negative word is mentioned, where the word \"like\" is used to convey the positive/negative nuance."
      ],
      "metadata": {
        "id": "RhbffQBs9cUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = analyze_sentiment(\"You smell like a flower\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M94HRCU56MLl",
        "outputId": "5b61bc80-a43b-4dbd-e8d4-24630d353ace"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = analyze_sentiment(\"You smell like a giraffe\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95yFnEdG6Q0-",
        "outputId": "ab6f50bf-9fc4-413a-b5dd-3fc19419b7b3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Negative test cases\n",
        "\n",
        "### 1. Empty string (no alphabet)\n",
        "It will return a null result. The inference process won't take place if the input doesn't include any alphabet."
      ],
      "metadata": {
        "id": "jckWfrY0wZBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = analyze_sentiment(\"    -     \")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnGkpgSPwh_X",
        "outputId": "984074f2-3a19-40d7-fb46-7fd2987a3374"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = analyze_sentiment(\"🤣👍👍\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiwfUxQ6w27l",
        "outputId": "91b30765-c081-40d2-c2cd-d2715694faa4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Texts containing emojis\n",
        "It will remove the emojis prior to the inference process to prevent"
      ],
      "metadata": {
        "id": "cxq_MqbixKhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = analyze_sentiment(\"This is really good 🤣👍👍\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipBYvqDzw7CG",
        "outputId": "78209157-c30e-40f8-a60f-29ae76380e06"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Sentences that are too long\n",
        "It will avoid giving ambiguous prediction result or having the model processing a large text, returning null value"
      ],
      "metadata": {
        "id": "-FrrHCbpx-uZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = analyze_sentiment('\"The quick brown fox jumps over the lazy dog\" is an English-language pangram – a sentence that contains all the letters of the alphabet. The phrase is commonly used for touch-typing practice, testing typewriters and computer keyboards, displaying examples of fonts, and other applications involving text where the use of all letters in the alphabet is desired.')\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClCjJLkPyY1Z",
        "outputId": "14ea5e0b-c7d3-46c6-a7ca-3fbc3f93a349"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    }
  ]
}